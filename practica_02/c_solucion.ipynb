{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "560e1319-08b9-4a63-b53c-5abc2152a0db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, StringType, BooleanType, DoubleType\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "096da5ea-ce05-4471-a7b9-365b02e5e802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|numero|cuadrado|\n",
      "+------+--------+\n",
      "|     2|       4|\n",
      "|     3|       9|\n",
      "|     4|      16|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la función cuadrado\n",
    "def cuadrado(num):\n",
    "    return num * num\n",
    "\n",
    "# Registrar la UDF\n",
    "cuadrado_udf = udf(cuadrado, IntegerType())\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = [(2,), (3,), (4,)]\n",
    "columns = [\"numero\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Usar la UDF en el DataFrame\n",
    "df.withColumn(\"cuadrado\", cuadrado_udf(df[\"numero\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17c3645d-f37a-4a19-a498-67d562423fe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "| cadena|longitud|\n",
      "+-------+--------+\n",
      "|   Hola|       4|\n",
      "|PySpark|       7|\n",
      "|  Mundo|       5|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la función longitud\n",
    "def longitud(cadena):\n",
    "    return len(cadena)\n",
    "\n",
    "# Registrar la UDF\n",
    "longitud_udf = udf(longitud, IntegerType())\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = [(\"Hola\",), (\"PySpark\",), (\"Mundo\",)]\n",
    "columns = [\"cadena\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Usar la UDF en el DataFrame\n",
    "df.withColumn(\"longitud\", longitud_udf(df[\"cadena\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d208fc5-8f31-4b41-807d-5357dab38e41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|numero|es_par|\n",
      "+------+------+\n",
      "|     2|  true|\n",
      "|     3| false|\n",
      "|     4|  true|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la función es_par\n",
    "def es_par(num):\n",
    "    return num % 2 == 0\n",
    "\n",
    "# Registrar la UDF\n",
    "es_par_udf = udf(es_par, BooleanType())\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = [(2,), (3,), (4,)]\n",
    "columns = [\"numero\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Usar la UDF en el DataFrame\n",
    "df.withColumn(\"es_par\", es_par_udf(df[\"numero\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c181f4-b462-451e-8187-b00048723f47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "| cadena|revertida|\n",
      "+-------+---------+\n",
      "|   Hola|     aloH|\n",
      "|PySpark|  krapSyP|\n",
      "|  Mundo|    odnuM|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la función revertir\n",
    "def revertir(cadena):\n",
    "    return cadena[::-1]\n",
    "\n",
    "# Registrar la UDF\n",
    "revertir_udf = udf(revertir, StringType())\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = [(\"Hola\",), (\"PySpark\",), (\"Mundo\",)]\n",
    "columns = [\"cadena\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Usar la UDF en el DataFrame\n",
    "df.withColumn(\"revertida\", revertir_udf(df[\"cadena\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "177c2d5f-86ba-49c0-85db-633154d168aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|radio|              area|\n",
      "+-----+------------------+\n",
      "|    1| 3.141592653589793|\n",
      "|    2|12.566370614359172|\n",
      "|    3|28.274333882308138|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la función calcular_area_circulo\n",
    "def calcular_area_circulo(radio):\n",
    "    return math.pi * radio**2\n",
    "\n",
    "# Registrar la UDF\n",
    "calcular_area_circulo_udf = udf(calcular_area_circulo, DoubleType())\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = [(1,), (2,), (3,)]\n",
    "columns = [\"radio\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Usar la UDF en el DataFrame\n",
    "df.withColumn(\"area\", calcular_area_circulo_udf(df[\"radio\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b9ec197-88bf-483e-a4b8-461333de2e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "| cadena|mayusculas|\n",
      "+-------+----------+\n",
      "|   hola|      HOLA|\n",
      "|pyspark|   PYSPARK|\n",
      "|  mundo|     MUNDO|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la función convertir_mayusculas\n",
    "def convertir_mayusculas(cadena):\n",
    "    return cadena.upper()\n",
    "\n",
    "# Registrar la UDF\n",
    "convertir_mayusculas_udf = udf(convertir_mayusculas, StringType())\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = [(\"hola\",), (\"pyspark\",), (\"mundo\",)]\n",
    "columns = [\"cadena\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Usar la UDF en el DataFrame\n",
    "df.withColumn(\"mayusculas\", convertir_mayusculas_udf(df[\"cadena\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "888165df-180b-4734-bb99-5eca95288652",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|anio_nacimiento|edad|\n",
      "+---------------+----+\n",
      "|           2000|  23|\n",
      "|           1990|  33|\n",
      "|           1985|  38|\n",
      "+---------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la función calcular_edad\n",
    "def calcular_edad(anio_nacimiento):\n",
    "    return 2023 - anio_nacimiento\n",
    "\n",
    "# Registrar la UDF\n",
    "calcular_edad_udf = udf(calcular_edad, IntegerType())\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = [(2000,), (1990,), (1985,)]\n",
    "columns = [\"anio_nacimiento\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Usar la UDF en el DataFrame\n",
    "df.withColumn(\"edad\", calcular_edad_udf(df[\"anio_nacimiento\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "878de70d-ff30-423d-9e0f-1fb70e4656de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|letra|es_vocal|\n",
      "+-----+--------+\n",
      "|    a|    true|\n",
      "|    b|   false|\n",
      "|    e|    true|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la función es_vocal\n",
    "def es_vocal(letra):\n",
    "    return letra.lower() in \"aeiou\"\n",
    "\n",
    "# Registrar la UDF\n",
    "es_vocal_udf = udf(es_vocal, BooleanType())\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = [(\"a\",), (\"b\",), (\"e\",)]\n",
    "columns = [\"letra\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Usar la UDF en el DataFrame\n",
    "df.withColumn(\"es_vocal\", es_vocal_udf(df[\"letra\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b3bb0cd-dce2-4c52-b61f-516c90a8824d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "practicas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
