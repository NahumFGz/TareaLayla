# En salas! Trabajaremos sobre la siguiente consigna:

Comprender y analizar las diferencias, ventajas y desventajas entre Apache Spark y Hadoop a nivel teórico, abordando aspectos como la arquitectura, el rendimiento, las capacidades y las aplicaciones de cada tecnología.

# Instrucciones:

## 1. Investigación de la Arquitectura:

- Apache Spark: Describe la arquitectura de Apache Spark, incluyendo componentes clave como el Driver, el Cluster Manager, y los Executors. Explica cómo Spark utiliza RDDs (Resilient Distributed Datasets) y DataFrames para el procesamiento de datos.
- Hadoop: Detalla la arquitectura de Hadoop, enfocándote en Hadoop Distributed File System (HDFS) y el modelo de procesamiento MapReduce. Explica el papel del NameNode, DataNode, JobTracker y TaskTracker.

## 2. Comparación de Rendimiento:

- Tiempo de Procesamiento: Compara el rendimiento de Spark y Hadoop en términos de tiempos de procesamiento para tareas comunes como el conteo de palabras, la agregación de datos y el filtrado.
- Manejo de Datos en Memoria vs. Disco: Explica cómo Spark maneja el procesamiento en memoria y cómo esto puede influir en el rendimiento frente al procesamiento en disco de Hadoop MapReduce.

## 3. Capacidades y Funcionalidades:

- Apache Spark: Analiza las capacidades adicionales de Spark, como el procesamiento en tiempo real (con Spark Streaming), el aprendizaje automático (con MLlib) y el análisis gráfico (con GraphX). Explica cómo estas funcionalidades extienden el alcance de Spark más allá del procesamiento por lotes.
- Hadoop: Describe las capacidades y funcionalidades de Hadoop, incluyendo la integración con herramientas del ecosistema como Hive, Pig y HBase. Discute cómo estas herramientas complementan el procesamiento MapReduce.

## 4. Casos de Uso:

- Apache Spark: Identifica y explica al menos dos casos de uso en los que Apache Spark es particularmente ventajoso, como el procesamiento de grandes volúmenes de datos en tiempo real o el análisis complejo de datos.
- Hadoop: Describe al menos dos escenarios en los que Hadoop MapReduce puede ser una opción adecuada, considerando aspectos como el almacenamiento de grandes volúmenes de datos en HDFS y el procesamiento por lotes.

## 5. Ventajas y Desventajas:

- Apache Spark: Enumera y discute las principales ventajas de Spark, como la velocidad de procesamiento y la capacidad de procesamiento en memoria. También, identifica y analiza las posibles desventajas, como el mayor consumo de memoria.
- Hadoop: Describe las ventajas de Hadoop, como la robustez y la escalabilidad de HDFS. Explica las desventajas relacionadas con el procesamiento MapReduce, como la latencia y la complejidad en la programación.

## 6. Informe de Resultados:

- Elabora un informe detallado que incluya tus hallazgos para cada uno de los aspectos mencionados. Utiliza diagramas, tablas y gráficos si es necesario para ilustrar las diferencias y comparaciones entre Apache Spark y Hadoop.
- Conclusión: Proporciona una conclusión general sobre cuándo y por qué elegirías uno u otro basado en el análisis realizado.
